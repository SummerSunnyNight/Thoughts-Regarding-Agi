v-jepa架构最重要的就是能把图像进行抽象的encoder和decoder。

yann lecun能提出这一点，我认为他已经触碰到人工智能进一步发展的一个很核心问题：人工智能如果想要理解图像，文字以及任何输入，mapping都不能在图像，文字本身来做。

这一点人类是怎么做的？我们看到图像看到的不是图像本身的那么多像素点，而是抽象成了我们脑海中的一个概念的映射。文字也一样，也是抽象成概念的映射。人类所有的传感器获得的信息，我们都只是用encoder在大脑存储为一个直观概念的映射而已。输出的时候我们也无法无损输出 **：这里用一个画画的例子特别合适，当你在画画的时候，实际上你只是心中有一个模糊的感觉和主题。如果你的decoder训练的特别完善（比如那些成熟的画师），你把这个decoder直接调用出来做一些微调就好了。**

 **微调** ：微调是什么，微调就是用你的encoder把你现在手上的这幅草稿画encode到你的大脑内部，你的内部会有个比较（计算损失函数？）的流程，看它现在的抽象标识是否符合你的心中的模糊的感觉和主题。

下面是一个事例，关于人的一般画画创作流程，大家可以思考一下有哪些是现在的人工智能还做不到的（未完待续），要让人工智能做到，需要哪些组件？：

1.你想要创造一幅表达爱和温暖的画。（为什么你想？人工智能无法有这样的自发的需求）

2在你的大脑内部，你见过很多画，但是你知道画也可以来自于画面，所以你一般都是在所有你经历过的画面，那些你encode过爱和温暖，而且你现在的缓存里面就能提取出来的进行search，在我的缓存中可以有下面的搜索结果：父母的付出，朋友的帮助，烈士的牺牲等等。你权衡了这里面哪个设计能表达到你期望的爱和温暖的程度 （同时还有别的限制，比如完成时间，成本，政治正确等）。如果有达到的方案就做，没有合适的方案就去搜索+思考。每次完成一部分修改以后都会用你的encoder map到大脑中和你的模糊主题计算损失函数，以校准结果。在这个过程中，训练出你（大脑中 爱和温暖 的画 的概念→爱和温暖的画）的decoder。

最难实现的是什么？是encoder和损失函数。我认为decoder现在的人工智能是可以实现的，无非就是一个分层的树。大脑内部的概念之间的联系，我认为也不难，就是一个对象的图。

encoder：父母的付出，朋友的帮助，烈士的牺牲怎么能encode到爱和温暖上去？爱和温暖的感受是一种基础的生理反应，它们都来自于生物体在困窘的境地时得到帮助。是一种多模态输入和人类基因共同耦合作用的结合。

损失函数：如果你画的画没有encode到爱和温暖上，你如何规划要怎么修改它来逼近？

未完待续
